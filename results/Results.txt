1. 	40000 de imagini, ratie 1:1
	Train test split: 80 20
	image_size: 32x32
	self.__model = Sequential()
        self.__model.add(Conv2D(32, kernel_size=(3, 3),
                                activation='relu',
                                kernel_initializer='he_normal',
                                input_shape=input_shape))
        self.__model.add(MaxPooling2D((2, 2)))
        self.__model.add(BatchNormalization())
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(64, (3, 3), activation='relu'))
        self.__model.add(MaxPooling2D(pool_size=(2, 2)))
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(128, (3, 3), activation='relu'))
        self.__model.add(Dropout(0.4))

        self.__model.add(Flatten())
        self.__model.add(Dense(128, activation='relu'))

        self.__model.add(Dropout(0.3))
        self.__model.add(Dense(2, activation='softmax'))
	
	self.__model.compile(loss="binary_crossentropy",
                             optimizer=keras.optimizers.Adam(lr=0.001),
                             metrics=['accuracy'])

        self.__history = self.__model.fit(
            X_train, Y_train,
            batch_size=32,
            epochs=100,
            validation_data=(X_test, Y_test))

	Train loss 0.0229294802993536
	Train accuracy 0.9961562752723694
	Test loss 0.14680969715118408
	Test accuracy 0.9570000171661377
	
	Confusion Matrix:
	[[3785  229]
 	[ 115 3871]]

2. 	100000 imagini, ratie 3:1
	Train test split: 80 20
	image_size: 32x32
	self.__model = Sequential()
        self.__model.add(Conv2D(32, kernel_size=(3, 3),
                                activation='relu',
                                kernel_initializer='he_normal',
                                input_shape=input_shape))
        self.__model.add(MaxPooling2D((2, 2)))
        self.__model.add(BatchNormalization())
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(64, (3, 3), activation='relu'))
        self.__model.add(MaxPooling2D(pool_size=(2, 2)))
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(128, (3, 3), activation='relu'))
        self.__model.add(Dropout(0.3))

        self.__model.add(Flatten())
        self.__model.add(Dense(128, activation='relu'))

        self.__model.add(Dropout(0.3))
        self.__model.add(Dense(2, activation='softmax'))

	self.__model.compile(loss="binary_crossentropy",
                             optimizer=keras.optimizers.Adam(lr=0.001),
                             metrics=['accuracy'])
	 self.__history = self.__model.fit(
            X_train, Y_train,
            batch_size=32,
            epochs=100,
            validation_data=(X_test, Y_test))

	Train loss 0.062083423137664795
	Train accuracy 0.9813125133514404
	Test loss 0.0932120680809021
	Test accuracy 0.9722499847412109
	
	Confusion Matrix:
	[[ 4517   509]
	 [   46 14928]]

3. 	100000 imagini, ratie 3:1
	Train test split: 80 20
	image_size: 64x64
	self.__model = Sequential()
        self.__model.add(Conv2D(64, kernel_size=(3, 3),
                                activation='relu',
                                kernel_initializer='he_normal',
                                input_shape=input_shape))
        self.__model.add(MaxPooling2D((2, 2)))
        self.__model.add(BatchNormalization())
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(64, (3, 3), activation='relu'))
        self.__model.add(MaxPooling2D(pool_size=(2, 2)))
        self.__model.add(Dropout(0.25))

        self.__model.add(Conv2D(128, (3, 3), activation='relu'))
        self.__model.add(Dropout(0.3))

        self.__model.add(Flatten())
        self.__model.add(Dense(128, activation='relu'))

        self.__model.add(Dropout(0.3))
        self.__model.add(Dense(2, activation='softmax'))

	self.__model.compile(loss="binary_crossentropy",
                             optimizer=keras.optimizers.Adam(lr=0.0001),
                             metrics=['accuracy'])

        self.__history = self.__model.fit(
            X_train, Y_train,
            batch_size=32,
            epochs=100,
            validation_data=(X_test, Y_test))
		
	Train loss 0.0020078232046216726
	Train accuracy 0.9998375177383423
	Test loss 0.09046542644500732
	Test accuracy 0.986299991607666
	
	Confusion Matrix:
	[[ 4819   207]
 	[   67 14907]]

4.  100000 imagini, ratie 3:1
    Train test split: 85 15
    image_size: 64x64
    self.__model = Sequential()
    self.__model.add(Conv2D(64, kernel_size=(3, 3),
                            activation='relu',
                            kernel_initializer='he_normal',
                            input_shape=input_shape))
    self.__model.add(MaxPooling2D((2, 2)))
    self.__model.add(BatchNormalization())
    self.__model.add(Dropout(0.25))

    self.__model.add(Conv2D(64, (3, 3), activation='relu'))
    self.__model.add(MaxPooling2D(pool_size=(2, 2)))
    self.__model.add(Dropout(0.25))

    self.__model.add(Conv2D(128, (3, 3), activation='relu'))
    self.__model.add(Dropout(0.3))

    self.__model.add(Flatten())
    self.__model.add(Dense(128, activation='relu'))

    self.__model.add(Dropout(0.3))
    self.__model.add(Dense(2, activation='softmax'))

	self.__model.compile(loss="binary_crossentropy",
                             optimizer=keras.optimizers.Adam(lr=0.0001),
                             metrics=['accuracy'])

        self.__history = self.__model.fit(
            X_train, Y_train,
            batch_size=32,
            epochs=50,
            validation_data=(X_test, Y_test))

	Train loss 0.005872439593076706
    Train accuracy 0.9989058971405029
    Test loss 0.07737772166728973
    Test accuracy 0.9850666522979736

	Confusion Matrix:
	[[ 3578   178]
    [   46 11198]]